{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select devices\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Bad to go!\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load config from config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "sys.path.append(os.getcwd())\n",
    "# choose between ship, lego\n",
    "import configs.ship, configs.lego\n",
    "sample_t: tuple = (2,6)\n",
    "scale_factor = 3\n",
    "# change config file here\n",
    "config = configs.lego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the dataset and show the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nerf.data import load_blender\n",
    "imgs, poses, int_mat = load_blender(config.datadir, device=DEVICE, scale_factor=scale_factor)\n",
    "img_n, img_h, img_w = imgs.shape[:3]\n",
    "# visualize\n",
    "plt.imshow(np.array(imgs[0].to(device=\"cpu\")))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"demo image\")\n",
    "plt.show()\n",
    "print(\"and its pose: \")\n",
    "print(np.array(poses[0].to(device=\"cpu\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rays\n",
    "from nerf.graphics import compute_rays\n",
    "\n",
    "rays_o, rays_d = compute_rays((img_h, img_w), int_mat, poses[0])\n",
    "print(\"origin: \", rays_o[0,0])\n",
    "print(\"normalized origin: \", F.normalize(rays_o[0,0], dim=0))\n",
    "print(\"center of ray: \", rays_d[img_h//2,img_w//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query from rays\n",
    "from nerf.graphics import queries_from_rays\n",
    "samples = None\n",
    "samples, depths = queries_from_rays(rays_o, rays_d, sample_t, 8)\n",
    "print(\"samples[0, 0]: \", samples[0,0])\n",
    "print(\"depths: \", depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pos encode\n",
    "\n",
    "from nerf.nerf_helper import *\n",
    "\n",
    "L = 6\n",
    "x = torch.tensor([[ 1.8013, -0.6242,  0.7009]])\n",
    "# x = torch.tensor([ 1.8013, -0.6242,  0.7009])\n",
    "enc_x = PosEncode(x, L, True)\n",
    "# enc_xx = PosEncode1(x, L, True)\n",
    "print(enc_x)\n",
    "# print(enc_xx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test render from nerf\n",
    "from nerf.graphics import render_from_nerf\n",
    "fake_depth = torch.Tensor([1])\n",
    "fake_nerf_output = imgs[0].cpu().reshape(img_h, img_w, 1, 4)\n",
    "rgb, depth = render_from_nerf(fake_nerf_output, fake_depth)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One iteration of TinyNeRF (forward pass).\n",
    "# TODO train\n",
    "# raise Exception(\"nothing wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.model import NeRF, TinyNeRF\n",
    "from nerf.nerf_helper import nerf_iter_once, tinynerf_iter_once\n",
    "import os.path\n",
    "\n",
    "###### parameters\n",
    "L_pos = 10\n",
    "L_dir = 4\n",
    "\n",
    "num_samples = 32\n",
    "batch_size = 512   # increase batchsize if u have large GPU MEM\n",
    "fc_width = 64\n",
    "fc_depth = 4\n",
    "skips = [2]\n",
    "\n",
    "lr = 5e-3\n",
    "# betas=(0.9, 0.999)\n",
    "num_it = 10000\n",
    "display_every = 200\n",
    "\n",
    "###### models\n",
    "model = NeRF(ch_in_pos=6*L_pos+3, ch_in_dir=6*L_dir+3, fc_width=fc_width, fc_depth=fc_depth, skips=skips)\n",
    "# model = TinyNeRF(6*L_pos+3, fc_width=128)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    # betas=betas,\n",
    ")\n",
    "seed = 9458\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "ckpt_path = 'nerf.pt'\n",
    "\n",
    "\n",
    "###### load validation data\n",
    "# imgs_val, poses_val, int_mat_val = load_blender(config.datadir, data_type=\"val\",scale_factor=2, device=DEVICE)\n",
    "# num_val = imgs_val.shape[0]\n",
    "val_idx = 1\n",
    "val_img = imgs[val_idx].to(DEVICE)\n",
    "val_c2w = poses[val_idx]\n",
    "\n",
    "###### train\n",
    "psnrs = []\n",
    "its = []\n",
    "i = 0\n",
    "\n",
    "###### check saved checkpoints\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(\"checkpoint found! Loading...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    i = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    psnrs = checkpoint['psnrs']\n",
    "    its = checkpoint['its']\n",
    "    print(\"checkpoint loaded, i =\",i)\n",
    "else:\n",
    "    print(\"No checkpoint found\")\n",
    "\n",
    "for i in range(i, num_it):\n",
    "    gt_img_idx = np.random.randint(100)\n",
    "    gt_img = imgs[gt_img_idx].to(DEVICE)\n",
    "    gt_c2w = poses[gt_img_idx]\n",
    "\n",
    "    pred_rgb,_ = nerf_iter_once(\n",
    "                model,\n",
    "                (img_h, img_w),\n",
    "                int_mat,\n",
    "                gt_c2w,\n",
    "                sample_t,\n",
    "                L_pos,\n",
    "                L_dir,\n",
    "                num_samples=num_samples,\n",
    "                batch_size=batch_size\n",
    "                )\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.nn.functional.mse_loss(pred_rgb, gt_img[...,:3])\n",
    "\n",
    "    # print(\"train_it:\", i, \"img_idx: \", gt_img_idx, \"loss:\",float(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % display_every == 0:\n",
    "        # val_idx = np.random.randint(num_val)\n",
    "        # val_img = imgs_val[val_idx].to(DEVICE)\n",
    "        # val_c2w = poses_val[val_idx]\n",
    "\n",
    "        pred_rgb,_ = nerf_iter_once(\n",
    "                model,\n",
    "                (img_h, img_w),\n",
    "                int_mat,\n",
    "                val_c2w,\n",
    "                sample_t,\n",
    "                L_pos,\n",
    "                L_dir,\n",
    "                num_samples=num_samples,\n",
    "                batch_size=batch_size\n",
    "                )\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(pred_rgb, val_img[...,:3])\n",
    "        print(\"Iteration \", i)\n",
    "        print(\"Val loss: \", loss)\n",
    "\n",
    "        psnr = -10. * torch.log10(loss)\n",
    "        psnrs.append(psnr.item())\n",
    "        its.append(i)\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(121)\n",
    "        img_np = pred_rgb.detach().cpu().numpy()\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"Iteration {i}\")\n",
    "        plt.subplot(122)\n",
    "        plt.plot(its, psnrs)\n",
    "        plt.title(\"PSNR\")\n",
    "        plt.show()\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'psnrs': psnrs,\n",
    "            'its': its\n",
    "            }, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
