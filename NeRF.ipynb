{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Tour to Neural Radiance Field (NeRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeRF is computation hungry, be sure to run this notebook on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select devices\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Bad to go!\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load config from config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "sys.path.append(os.getcwd())\n",
    "# choose between hotdog, lego\n",
    "import configs.hotdog, configs.lego\n",
    "sample_t: tuple = (2,6)\n",
    "\n",
    "#### Modify: scale_factor, config ###\n",
    "# 100x100: scale_factor=3\n",
    "# 200x200:scale_factor=2\n",
    "scale_factor = 3\n",
    "# change config file here\n",
    "config = configs.lego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the dataset and show the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nerf.data import load_blender\n",
    "imgs, poses, int_mat = load_blender(config.datadir, device=\"cpu\", scale_factor=scale_factor)\n",
    "img_n, img_h, img_w = imgs.shape[:3]\n",
    "# visualize\n",
    "plt.imshow(np.array(imgs[0].to(device=\"cpu\")))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"demo image\")\n",
    "plt.show()\n",
    "print(\"and its pose: \")\n",
    "print(np.array(poses[0].to(device=\"cpu\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rays\n",
    "from nerf.graphics import compute_rays\n",
    "\n",
    "rays_o, rays_d = compute_rays((img_h, img_w), int_mat, poses[0])\n",
    "print(\"origin: \", rays_o[0,0])\n",
    "print(\"normalized origin: \", F.normalize(rays_o[0,0], dim=0))\n",
    "print(\"center of ray: \", rays_d[img_h//2,img_w//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query from rays\n",
    "from nerf.graphics import queries_from_rays\n",
    "samples = None\n",
    "samples, depths = queries_from_rays(rays_o, rays_d, sample_t, 8)\n",
    "print(\"samples[0, 0]: \", samples[0,0])\n",
    "# print(\"depths: \", depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pos encode\n",
    "\n",
    "from nerf.nerf_helper import *\n",
    "\n",
    "L = 6\n",
    "x = torch.tensor([[ 1.8013, -0.6242,  0.7009]])\n",
    "# x = torch.tensor([ 1.8013, -0.6242,  0.7009])\n",
    "enc_x = PosEncode(x, L, True)\n",
    "# enc_xx = PosEncode1(x, L, True)\n",
    "print(enc_x)\n",
    "# print(enc_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test render from nerf\n",
    "from nerf.graphics import render_from_nerf\n",
    "fake_depth = torch.Tensor([1])\n",
    "fake_nerf_output = imgs[0].cpu().reshape(img_h, img_w, 1, 4)\n",
    "rgb, depth = render_from_nerf(fake_nerf_output, fake_depth)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.model import NeRF \n",
    "import os.path\n",
    "\n",
    "seed = 9458\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "###### hyper-parameters\n",
    "L_pos = 10\n",
    "L_dir = 4\n",
    "num_samples = 32\n",
    "batch_size = 8192 # increase batchsize if u have large GPU MEM\n",
    "fc_width = 128\n",
    "fc_depth = 4\n",
    "skips = [2]\n",
    "lr = 5e-4\n",
    "num_it = 10001\n",
    "display_every = 200\n",
    "\n",
    "###### models\n",
    "model = NeRF(ch_in_pos=6*L_pos+3, ch_in_dir=6*L_dir+3, fc_width=fc_width, fc_depth=fc_depth, skips=skips)\n",
    "model.to(DEVICE)\n",
    "\n",
    "###### load validation data\n",
    "imgs_val, poses_val, _ = load_blender(config.datadir, data_type=\"val\",scale_factor=scale_factor, device=\"cpu\")\n",
    "num_val = imgs_val.shape[0]\n",
    "\n",
    "###### train\n",
    "psnrs = []\n",
    "val_its = []\n",
    "i = 0\n",
    "\n",
    "###### optimizer, checkpoint\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr)\n",
    "ckpt_path = 'nerf.pt'\n",
    "\n",
    "###### check saved checkpoints\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(\"checkpoint found! Loading...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    i = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    psnrs = checkpoint['psnrs']\n",
    "    val_its = checkpoint['its']\n",
    "    print(\"checkpoint loaded, i =\",i)\n",
    "else:\n",
    "    print(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.training_logic import train_NeRF\n",
    "train_NeRF(model = model, optimizer=optimizer,imgs_train=imgs, imgs_val=imgs_val, poses_train=poses, poses_val=poses_val,int_mat=int_mat, sample_t=sample_t,\n",
    "            L_pos=L_pos, L_dir=L_dir, num_samples=num_samples, ckpt_path=ckpt_path, batch_size=batch_size,\n",
    "            psnrs=psnrs, val_its=val_its, start_iter_num=i, end_iter_num=num_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"nothing wrong\")\n",
    "# Select model\n",
    "ckpt_path = 'nerf.pt' # './trained_models/basic_nerf_lego_9800.pt'\n",
    "# change config file\n",
    "config = configs.lego\n",
    "\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(ckpt_path, \"found! Loading...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    i = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    psnrs = checkpoint['psnrs']\n",
    "    its = checkpoint['its']\n",
    "    print(\"checkpoint loaded, i =\",i)\n",
    "else:\n",
    "    print(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.graphics import generate_demo_poses\n",
    "from nerf.nerf_helper import nerf_iter_once\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "# generate pose\n",
    "model.eval()\n",
    "gen_num: int = 120\n",
    "repeat: int = 2\n",
    "gen_poses:Tensor = generate_demo_poses(height=4, num_poses=gen_num).to(poses).to(DEVICE)\n",
    "gen_imgs:list = []\n",
    "for i in range(gen_num):\n",
    "    with torch.no_grad():\n",
    "        pred_rgb, pred_depth = nerf_iter_once(\n",
    "                model,\n",
    "                (img_h, img_w),\n",
    "                int_mat.to(DEVICE),\n",
    "                gen_poses[i],\n",
    "                sample_t,\n",
    "                L_pos,\n",
    "                L_dir,\n",
    "                num_samples=num_samples,\n",
    "                batch_size=batch_size\n",
    "                )\n",
    "    # concat channels\n",
    "    pred_rgbd: Tensor = torch.cat([pred_rgb, pred_depth[...,None]], dim=-1)\n",
    "    # translate to [0,255]\n",
    "    img_np = np.array(pred_rgbd.detach().cpu()*255).astype(np.uint8)\n",
    "    img_np = cv2.resize(img_np, (112,112), interpolation=cv2.INTER_AREA)\n",
    "    gen_imgs.append(img_np)\n",
    "\n",
    "gen_imgs = gen_imgs * repeat\n",
    "\n",
    "imageio.mimwrite('{}.mp4'.format(config.expname), gen_imgs, fps=30, quality=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
