{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select devices\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Bad to go!\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load config from config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "sys.path.append(os.getcwd())\n",
    "# choose between hotdog, lego\n",
    "import configs.hotdog, configs.lego\n",
    "sample_t: tuple = (2,6)\n",
    "\n",
    "#### Modify: scale_factor, config ###\n",
    "# 100x100: scale_factor=3\n",
    "# 200x200:scale_factor=2\n",
    "scale_factor = 3\n",
    "# change config file here\n",
    "config = configs.lego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the dataset and show the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nerf.data import load_blender\n",
    "imgs, poses, int_mat = load_blender(config.datadir, device=\"cpu\", scale_factor=scale_factor)\n",
    "img_n, img_h, img_w = imgs.shape[:3]\n",
    "# visualize\n",
    "plt.imshow(np.array(imgs[0].to(device=\"cpu\")))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"demo image\")\n",
    "plt.show()\n",
    "print(\"and its pose: \")\n",
    "print(np.array(poses[0].to(device=\"cpu\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rays\n",
    "from nerf.graphics import compute_rays\n",
    "\n",
    "rays_o, rays_d = compute_rays((img_h, img_w), int_mat, poses[0])\n",
    "print(\"origin: \", rays_o[0,0])\n",
    "print(\"normalized origin: \", F.normalize(rays_o[0,0], dim=0))\n",
    "print(\"center of ray: \", rays_d[img_h//2,img_w//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query from rays\n",
    "from nerf.graphics import queries_from_rays\n",
    "samples = None\n",
    "samples, depths = queries_from_rays(rays_o, rays_d, sample_t, 8)\n",
    "print(\"samples[0, 0]: \", samples[0,0])\n",
    "# print(\"depths: \", depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pos encode\n",
    "\n",
    "from nerf.nerf_helper import *\n",
    "\n",
    "L = 6\n",
    "x = torch.tensor([[ 1.8013, -0.6242,  0.7009]])\n",
    "# x = torch.tensor([ 1.8013, -0.6242,  0.7009])\n",
    "enc_x = PosEncode(x, L, True)\n",
    "# enc_xx = PosEncode1(x, L, True)\n",
    "print(enc_x)\n",
    "# print(enc_xx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test render from nerf\n",
    "from nerf.graphics import render_from_nerf\n",
    "fake_depth = torch.Tensor([1])\n",
    "fake_nerf_output = imgs[0].cpu().reshape(img_h, img_w, 1, 4)\n",
    "rgb, depth = render_from_nerf(fake_nerf_output, fake_depth)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One iteration of TinyNeRF (forward pass).\n",
    "# TODO train\n",
    "# raise Exception(\"nothing wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.model import NeRF, TinyNeRF\n",
    "import os.path\n",
    "\n",
    "###### parameters\n",
    "L_pos = 10\n",
    "L_dir = 4\n",
    "\n",
    "num_samples = 128\n",
    "batch_size = 8192 # increase batchsize if u have large GPU MEM\n",
    "fc_width = 128\n",
    "fc_depth = 4\n",
    "skips = [2]\n",
    "\n",
    "lr = 5e-4\n",
    "# betas=(0.9, 0.999)\n",
    "num_it = 10001\n",
    "display_every = 200\n",
    "\n",
    "###### models\n",
    "model = NeRF(ch_in_pos=6*L_pos+3, ch_in_dir=6*L_dir+3, fc_width=fc_width, fc_depth=fc_depth, skips=skips)\n",
    "# model = TinyNeRF(6*L_pos+3, fc_width=128)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    # betas=betas,\n",
    ")\n",
    "seed = 9458\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "ckpt_path = 'nerf.pt'\n",
    "\n",
    "\n",
    "###### load validation data\n",
    "imgs_val, poses_val, int_mat_val = load_blender(config.datadir, data_type=\"val\",scale_factor=scale_factor, device=\"cpu\")\n",
    "num_val = imgs_val.shape[0]\n",
    "# val_idx = 1\n",
    "# val_img = imgs[val_idx].to(DEVICE)\n",
    "# val_c2w = poses[val_idx]\n",
    "\n",
    "###### train\n",
    "psnrs = []\n",
    "its = []\n",
    "i = 0\n",
    "\n",
    "###### check saved checkpoints\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(\"checkpoint found! Loading...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    i = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    psnrs = checkpoint['psnrs']\n",
    "    its = checkpoint['its']\n",
    "    print(\"checkpoint loaded, i =\",i)\n",
    "else:\n",
    "    print(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step():\n",
    "    gt_img_idx = np.random.randint(100)\n",
    "    gt_img = imgs[gt_img_idx].clone().to(DEVICE)\n",
    "    gt_c2w = poses[gt_img_idx].clone().to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_rgb,_ = nerf_iter_once(\n",
    "                model,\n",
    "                (img_h, img_w),\n",
    "                int_mat.to(DEVICE),\n",
    "                gt_c2w,\n",
    "                sample_t,\n",
    "                L_pos,\n",
    "                L_dir,\n",
    "                num_samples=num_samples,\n",
    "                batch_size=batch_size\n",
    "                )\n",
    "    loss = torch.nn.functional.mse_loss(pred_rgb, gt_img[...,:3])\n",
    "\n",
    "    # print(\"train_it:\", i, \"img_idx: \", gt_img_idx, \"loss:\",float(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def val_one_step(i):\n",
    "\tval_idx = np.random.randint(num_val)\n",
    "\tval_img = imgs_val[val_idx].clone().to(DEVICE)\n",
    "\tval_c2w = poses_val[val_idx].clone().to(DEVICE)\n",
    "\n",
    "\tpred_rgb,_ = nerf_iter_once(\n",
    "\t\t\tmodel,\n",
    "\t\t\t(img_h, img_w),\n",
    "\t\t\tint_mat_val.to(DEVICE),\n",
    "\t\t\tval_c2w,\n",
    "\t\t\tsample_t,\n",
    "\t\t\tL_pos,\n",
    "\t\t\tL_dir,\n",
    "\t\t\tnum_samples=num_samples,\n",
    "\t\t\tbatch_size=batch_size\n",
    "\t\t\t)\n",
    "\n",
    "\tloss = torch.nn.functional.mse_loss(pred_rgb, val_img[...,:3])\n",
    "\tprint(\"Iteration \", i)\n",
    "\tprint(\"Val loss: \", loss)\n",
    "\n",
    "\tpsnr = -10. * torch.log10(loss)\n",
    "\tpsnrs.append(psnr.item())\n",
    "\tits.append(i)\n",
    "\n",
    "\tplt.figure(figsize=(10, 4))\n",
    "\tplt.subplot(121)\n",
    "\timg_np = pred_rgb.detach().cpu().numpy()\n",
    "\tplt.imshow(img_np)\n",
    "\tplt.title(f\"Iteration {i}\")\n",
    "\tplt.subplot(122)\n",
    "\tplt.plot(its, psnrs)\n",
    "\tplt.title(\"PSNR\")\n",
    "\tplt.show()\n",
    "\n",
    "\ttorch.save({\n",
    "\t\t'epoch': i,\n",
    "\t\t'model_state_dict': model.state_dict(),\n",
    "\t\t'optimizer_state_dict': optimizer.state_dict(),\n",
    "\t\t'loss': loss,\n",
    "\t\t'psnrs': psnrs,\n",
    "\t\t'its': its}, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(i, num_it)):\n",
    "    if i % display_every == 0:\n",
    "        val_one_step(i)\n",
    "    else:\n",
    "        train_one_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"nothing wrong\")\n",
    "# Select model\n",
    "ckpt_path = 'nerf.pt' # './trained_models/basic_nerf_lego_9800.pt'\n",
    "# change config file\n",
    "config = configs.lego\n",
    "\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(ckpt_path, \"found! Loading...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    i = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    psnrs = checkpoint['psnrs']\n",
    "    its = checkpoint['its']\n",
    "    print(\"checkpoint loaded, i =\",i)\n",
    "else:\n",
    "    print(\"No checkpoint found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerf.graphics import generate_demo_poses\n",
    "from nerf.nerf_helper import nerf_iter_once\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "# generate pose\n",
    "model.eval()\n",
    "gen_num: int = 120\n",
    "repeat: int = 2\n",
    "gen_poses:Tensor = generate_demo_poses(height=4, num_poses=gen_num).to(poses).to(DEVICE)\n",
    "gen_imgs:list = []\n",
    "for i in range(gen_num):\n",
    "    with torch.no_grad():\n",
    "        pred_rgb, pred_depth = nerf_iter_once(\n",
    "                model,\n",
    "                (img_h, img_w),\n",
    "                int_mat_val.to(DEVICE),\n",
    "                gen_poses[i],\n",
    "                sample_t,\n",
    "                L_pos,\n",
    "                L_dir,\n",
    "                num_samples=num_samples,\n",
    "                batch_size=batch_size\n",
    "                )\n",
    "    # concat channels\n",
    "    pred_rgbd: Tensor = torch.cat([pred_rgb, pred_depth[...,None]], dim=-1)\n",
    "    # translate to [0,255]\n",
    "    img_np = np.array(pred_rgbd.detach().cpu()*255).astype(np.uint8)\n",
    "    img_np = cv2.resize(img_np, (112,112), interpolation=cv2.INTER_AREA)\n",
    "    gen_imgs.append(img_np)\n",
    "\n",
    "gen_imgs = gen_imgs * repeat\n",
    "\n",
    "imageio.mimwrite('{}.mp4'.format(config.expname), gen_imgs, fps=30, quality=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
