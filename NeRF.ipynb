{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select devices\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Good to go!\")\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Bad to go!\")\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load config from config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "sys.path.append(os.getcwd())\n",
    "# choose between ship, lego\n",
    "import configs.ship, configs.lego\n",
    "# change config file here\n",
    "config = configs.lego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the dataset and show the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nerf.data import load_blender\n",
    "imgs, poses, int_mat = load_blender(config.datadir, device=DEVICE)\n",
    "img_n, img_h, img_w = imgs.shape[:3]\n",
    "# visualize\n",
    "plt.imshow(np.array(imgs[0].to(device=\"cpu\")))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"demo image\")\n",
    "plt.show()\n",
    "print(\"and its pose: \")\n",
    "print(np.array(poses[0].to(device=\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_rays(H, W, K, c2w):\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))  # pytorch's meshgrid has indexing='ij'\n",
    "    i = i.t().to(K.device)\n",
    "    j = j.t().to(K.device)\n",
    "    dirs = torch.stack([(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -torch.ones_like(i)], -1)\n",
    "    print(dirs.shape)\n",
    "    print(dirs[..., None, :].shape)\n",
    "    # Rotate ray directions from camera frame to the world frame\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    print(rays_d.shape)\n",
    "    # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "    return rays_o, rays_d\n",
    "\n",
    "o, d = get_rays(img_h, img_w, int_mat, poses[0])\n",
    "rays = torch.stack([get_rays(img_h, img_w, int_mat, p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8912,  0.4536,  0.8085, -0.5885,  0.9320,  0.3624,  0.6755, -0.7374,\n",
      "          0.9636,  0.2675,  0.5155, -0.8569],\n",
      "        [ 0.8632, -0.5048, -0.8716, -0.4903,  0.8085, -0.5885, -0.9516, -0.3073,\n",
      "          0.7457, -0.6663, -0.9937, -0.1122]])\n"
     ]
    }
   ],
   "source": [
    "# test posencode\n",
    "\n",
    "from nerf_helper import PosEncode\n",
    "\n",
    "L = 2\n",
    "x = torch.tensor([[1.1, 1.2, 1.3], [2.1, 2.2, 2.3]])\n",
    "enc_x = PosEncode(x, L)\n",
    "\n",
    "print(enc_x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
